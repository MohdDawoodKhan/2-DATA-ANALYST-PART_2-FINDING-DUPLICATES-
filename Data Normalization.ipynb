{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7e9081-b42f-4ad1-96ab-2b1c0d77b56d",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707e741-3900-42bf-af46-46c520ff6347",
   "metadata": {},
   "source": [
    "### Step 1: Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe85f8-4fd4-47fd-9d9d-41e69e5a2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a4e6e-23d9-47af-b06d-3e59a35ab7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd9965-f828-4dba-a117-6480930df0ae",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584ae9e-fa8f-4a13-a21d-26038eb2ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to check if data is loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ead79-7e19-45ca-970c-b9a86002b608",
   "metadata": {},
   "source": [
    "### Section 1: Handling Duplicates\n",
    "#### Task 1: Identify and remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc554aea-c079-4ba5-a5ba-55a119726a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "dup = df[df.duplicated()] \n",
    "print(\"duplicate value\") \n",
    "print(dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8437aff6-266c-4b78-8199-dd32628a0ffa",
   "metadata": {},
   "source": [
    "### Section 2: Handling Missing Values\n",
    "#### Task 2: Identify missing values in CodingActivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de6783-47c1-44a7-978d-4af6539f5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "cod_mis = df['CodingActivities'].isnull().sum() \n",
    "print(\"missing value in CodingActivities\") \n",
    "print(cod_mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2853221-555d-40ba-bea7-aa1a98c567a4",
   "metadata": {},
   "source": [
    "#### Task 3: Impute missing values in CodingActivities with forward-fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efebbd-ca4f-4b9f-ba14-b2ad14c205c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "df['CodingActivities'].fillna(method='ffill' , inplace = True) \n",
    "print(df['CodingActivities'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea94b3-e385-4ebf-aa53-7a5255e5edf5",
   "metadata": {},
   "source": [
    "##### Note: Before normalizing ConvertedCompYearly, ensure that any missing values (NaN) in this column are handled appropriately. You can choose to either drop the rows containing NaN or replace the missing values with a suitable statistic (e.g., median or mean).\n",
    "\n",
    "### Section 3: Normalizing Compensation Data\n",
    "#### Task 4: Identify compensation-related columns, such as ConvertedCompYearly.\n",
    "##### Normalization is commonly applied to compensation data to bring values within a comparable range. Here, you’ll identify ConvertedCompYearly or similar columns, which contain compensation information. This column will be used in the subsequent tasks for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0a70d-c932-4a9e-b745-baecd697319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "print(df.columns)\n",
    "comp_col = [col for col in df.columns if 'comp' in col.lower() or 'salary' in col.lower() or 'pay' in col.lower()] \n",
    "print(\"compensation related col\") \n",
    "print(comp_col) \n",
    "comp_mis = df['ConvertedCompYearly'].isnull().sum() \n",
    "print(\"missing value in ConvertedCompYearl\") \n",
    "print(comp_mis) \n",
    "mean_val = df['ConvertedCompYearly'].mean() \n",
    "df['ConvertedCompYearly'].fillna(mean_val , inplace=True) \n",
    "print(\"after fill \") \n",
    "print(df['ConvertedCompYearly'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76449bb4-1c80-4ae8-aba8-9beae61cb929",
   "metadata": {},
   "source": [
    "#### Task 5: Normalize ConvertedCompYearly using Min-Max Scaling.\n",
    "##### Min-Max Scaling brings all values in a column to a 0-1 range, making it useful for comparing data across different scales. Here, you will apply Min-Max normalization to the ConvertedCompYearly column, creating a new column ConvertedCompYearly_MinMax with normalized values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded00f38-79af-4e66-81e1-ae1e44300852",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "scaler = MinMaxScaler() \n",
    "df['ConvertedCompYearly_MinMax'] = scaler.fit_transform(df[['ConvertedCompYearly']]) \n",
    "print(df['ConvertedCompYearly']) \n",
    "print(df['ConvertedCompYearly_MinMax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad251d7-810f-47d3-b6ed-a5145122837c",
   "metadata": {},
   "source": [
    "#### Task 6: Apply Z-score Normalization to ConvertedCompYearly.\n",
    "##### Z-score normalization standardizes values by converting them to a distribution with a mean of 0 and a standard deviation of 1. This method is helpful for datasets with a Gaussian (normal) distribution. Here, you’ll calculate Z-scores for the ConvertedCompYearly column, saving the results in a new column ConvertedCompYearly_Zscore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce95963-91fc-4ea5-be5e-30aabb33698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "mean = df['ConvertedCompYearly'].mean() \n",
    "std = df['ConvertedCompYearly'].std() \n",
    "df['ConvertedCompYearly_Zscore'] = (df['ConvertedCompYearly'] - mean)/ std \n",
    "print(df['ConvertedCompYearly_Zscore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883d8e3-37ef-4202-bb42-5ce2ed1caed4",
   "metadata": {},
   "source": [
    "### Section 4: Visualization of Normalized Data\n",
    "#### Task 7: Visualize the distribution of ConvertedCompYearly, ConvertedCompYearly_Normalized, and ConvertedCompYearly_Zscore\n",
    "##### Visualization helps you understand how normalization changes the data distribution. In this task, create histograms for the original ConvertedCompYearly, as well as its normalized versions (ConvertedCompYearly_MinMax and ConvertedCompYearly_Zscore). This will help you compare how each normalization technique affects the data range and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a15f0-101f-4285-9075-c499c44bc7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
